{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b80f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS = 100\n",
    "HL_SIZE = 32\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a139e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # output logits (no sigmoid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out  # logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NN(input_size=7, hidden_size=HL_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779ebf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from model.pth\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pth'))\n",
    "print(\"Model loaded from model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a0b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data.txt', delimiter=',', dtype=np.float32)\n",
    "X, y = torch.tensor(data[:, :-1], dtype=torch.float32), torch.tensor(data[:, -1], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X, y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "pos = (y == 1).sum().item()\n",
    "neg = (y == 0).sum().item()\n",
    "pos_weight = torch.tensor([neg / max(pos, 1)], device=device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0\n",
    "    idx = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)  # raw scores\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        idx += 1\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{EPOCHS}], Step [{idx}/{len(train_loader)}], Loss: {loss_sum/idx:.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {loss_sum/len(train_loader):.4f}\")\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')\n",
    "        print(f\"Model saved to model_epoch_{epoch}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "874b12e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 1600373, TN: 1759429, FP: 15287, FN: 5473010\n",
      "Overall accuracy: 0.3797\n",
      "False cutoff rate: 0.0086\n",
      "Trustworthiness: 0.9905\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "tot_tp, tot_tn, tot_fp, tot_fn = 0, 0, 0, 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits = model(inputs)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.9).float()\n",
    "        # Compute metrics here\n",
    "        tp = ((preds == 1) & (labels == 1)).sum().item()\n",
    "        tn = ((preds == 0) & (labels == 0)).sum().item()\n",
    "        fp = ((preds == 1) & (labels == 0)).sum().item()\n",
    "        fn = ((preds == 0) & (labels == 1)).sum().item()\n",
    "        # Print or store the metrics as needed\n",
    "        tot_tp += tp\n",
    "        tot_tn += tn\n",
    "        tot_fp += fp\n",
    "        tot_fn += fn\n",
    "\n",
    "print(f\"TP: {tot_tp}, TN: {tot_tn}, FP: {tot_fp}, FN: {tot_fn}\")\n",
    "print(f\"Overall accuracy: {(tot_tp + tot_tn) / (tot_tp + tot_tn + tot_fp + tot_fn):.4f}\")\n",
    "print(f\"False cutoff rate: {tot_fp / (tot_fp + tot_tn):.4f}\")\n",
    "print(f\"Trustworthiness: {tot_tp / (tot_tp + tot_fp):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30fa5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constexpr float fc1_w[32][7] = {\n",
      "  {-0.142832f, 0.257207f, 3.059942f, 2.634154f, -0.280495f, -0.291688f, -0.338926f},\n",
      "  {2.014827f, 0.003721f, 7.907294f, -3.755454f, -0.046315f, -1.958439f, -0.009919f},\n",
      "  {-0.305199f, -0.075899f, -2.393071f, 0.447503f, -0.010461f, 0.207258f, 0.114630f},\n",
      "  {-0.855188f, -0.245207f, 1.158329f, -5.867863f, 0.273297f, 1.084720f, 0.312102f},\n",
      "  {-3.321608f, 0.032172f, 3.490289f, 3.068175f, -0.034605f, 3.352406f, -0.116044f},\n",
      "  {-0.514411f, -0.204998f, -0.000549f, -5.308782f, 0.207224f, 0.989027f, 0.180521f},\n",
      "  {-3.171893f, -0.007797f, 0.546640f, -5.410606f, -0.009987f, -3.278243f, 0.005597f},\n",
      "  {-0.038320f, -0.356003f, -0.210976f, -3.554320f, 0.069527f, -0.853302f, -0.122736f},\n",
      "  {0.174251f, 0.183640f, 0.764978f, 5.484465f, -0.029347f, 0.479122f, 0.061596f},\n",
      "  {1.197889f, -0.002775f, 7.744094f, -20.791843f, 0.042538f, 0.414730f, 0.000301f},\n",
      "  {0.186771f, 0.190327f, -0.823688f, -0.061686f, -0.135967f, 2.359247f, 0.346188f},\n",
      "  {-0.522338f, 0.056001f, -2.260973f, 0.619349f, -0.008087f, -0.069698f, 0.235311f},\n",
      "  {1.803113f, -0.055591f, 5.078661f, -4.385397f, 0.017168f, -3.136999f, -0.131653f},\n",
      "  {-0.357038f, 0.117698f, 0.727825f, 1.490023f, -0.123332f, -0.129628f, 0.284226f},\n",
      "  {-1.895267f, 0.200234f, -5.016572f, 1.020235f, -0.023792f, -9.580444f, -0.000976f},\n",
      "  {-0.934542f, -0.219938f, 9.362362f, 1.459580f, 0.224935f, -0.053798f, 0.001014f},\n",
      "  {0.714447f, 0.261212f, 1.722526f, 2.943616f, 0.065332f, 1.247544f, 0.002526f},\n",
      "  {-0.117763f, -0.211573f, 1.267874f, -5.925147f, 0.432492f, 0.850562f, 0.236126f},\n",
      "  {0.415325f, -0.064900f, 5.726271f, -1.883600f, 0.034958f, 4.303244f, -0.002447f},\n",
      "  {0.709863f, 0.295463f, 1.138073f, -0.845519f, -0.321137f, -0.231291f, 0.191094f},\n",
      "  {0.013509f, -0.190240f, 4.251653f, -4.244159f, 0.188617f, -0.533442f, 0.167414f},\n",
      "  {1.650517f, -0.040617f, -2.824463f, 10.730221f, 0.137668f, -3.069502f, 0.037945f},\n",
      "  {-0.722725f, -0.255499f, 0.533289f, 1.148501f, 0.223535f, 2.634296f, 0.214035f},\n",
      "  {0.827557f, -0.000058f, -2.950690f, -30.575588f, 0.002991f, 0.032074f, -0.000153f},\n",
      "  {-0.237998f, 0.228535f, 0.342428f, 2.897483f, -0.228552f, -0.079448f, 0.225023f},\n",
      "  {1.982302f, 0.343568f, 0.111717f, 5.144579f, -0.427439f, -0.665045f, -0.003446f},\n",
      "  {0.822356f, 0.296949f, 1.334282f, -1.938932f, -0.288040f, 0.532559f, -0.244190f},\n",
      "  {-0.940136f, 0.090728f, -0.600615f, 2.501339f, -0.341855f, -6.710108f, -0.074759f},\n",
      "  {0.309810f, 0.181533f, -0.045532f, -8.057179f, 0.019244f, 2.765787f, -0.153658f},\n",
      "  {-0.815640f, -0.155220f, 0.903187f, -12.152477f, 0.071233f, -1.520937f, 0.250753f},\n",
      "  {-0.917389f, -0.170363f, 1.365956f, 3.357368f, 0.225091f, 1.145253f, -0.105320f},\n",
      "  {-0.087426f, 0.222018f, -0.312771f, -1.032508f, -0.236361f, -0.580129f, 0.113310f}\n",
      "};\n",
      "constexpr float fc1_b[] = {1.7085790634155273, 2.587620496749878, -0.7445627450942993, 1.7781389951705933, -1.9525152444839478, -0.3068484365940094, 2.2659735679626465, -2.5765223503112793, 0.5613479614257812, 2.2933108806610107, -0.476116418838501, -1.6334234476089478, 2.936504364013672, 0.30294281244277954, -3.3533332347869873, 0.15879014134407043, 1.2219886779785156, -0.5361279249191284, 3.574019193649292, -0.8913733959197998, 1.2804372310638428, -0.8248299956321716, 0.007099098991602659, -0.7946221232414246, 0.3388253450393677, 3.272510051727295, -1.6711374521255493, -0.11329231411218643, -0.7462398409843445, 0.06612244248390198, 0.3033437728881836, 0.3164454698562622};\n",
      "constexpr float fc2_w[1][32] = {\n",
      "  {-0.054201f, -0.123626f, -0.033561f, 0.057325f, -0.034591f, -0.090571f, 0.154498f, 0.100263f, -0.139465f, 0.341349f, 0.121447f, 0.033315f, 0.029058f, -0.136044f, -0.058097f, -0.114548f, 0.074730f, -0.016350f, -0.074516f, 0.160147f, 0.053767f, 0.070611f, -0.037279f, -0.693982f, -0.117810f, 0.057470f, 0.035309f, -0.029260f, 0.039189f, 0.040563f, -0.048563f, -0.138627f}\n",
      "};\n",
      "constexpr float fc2_b = -0.7302433848381042;\n"
     ]
    }
   ],
   "source": [
    "fc1_w = model.fc1.weight.detach().cpu().numpy()\n",
    "fc1_b = model.fc1.bias.detach().cpu().numpy()\n",
    "fc2_w = model.fc2.weight.detach().cpu().numpy()\n",
    "fc2_b = model.fc2.bias.detach().cpu().numpy()\n",
    "\n",
    "# print the raw float weights in c-style array to be copy pasted\n",
    "print(\"constexpr float fc1_w[\" + str(fc1_w.shape[0]) + \"][\" + str(fc1_w.shape[1]) + \"] = {\")\n",
    "for i, row in enumerate(fc1_w):\n",
    "    print(\"  {\" + \", \".join(f\"{w:.6f}f\" for w in row) + \"}\" + (\",\" if i < len(fc1_w) - 1 else \"\"))\n",
    "print(\"};\")\n",
    "print(\"constexpr float fc1_b[] = {\" + \", \".join(f\"{b}\" for b in fc1_b) + \"};\")\n",
    "print(\"constexpr float fc2_w[\" + str(fc2_w.shape[0]) + \"][\" + str(fc2_w.shape[1]) + \"] = {\")\n",
    "for i, row in enumerate(fc2_w):\n",
    "    print(\"  {\" + \", \".join(f\"{w:.6f}f\" for w in row) + \"}\" + (\",\" if i < len(fc2_w) - 1 else \"\"))\n",
    "print(\"};\")\n",
    "print(\"constexpr float fc2_b = \" + \", \".join(f\"{b}\" for b in fc2_b) + \";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
